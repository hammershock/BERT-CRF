# 基于Transformer的命名实体识别

三种模型结构：
1. 编码器BERT
2. 解码器GPT
3. 编码器+解码器T5

- 层数超参数自选，
- 随机初始化/预训练
- 有CRF，无CRF

提交：

- [x]: 
1. 文档（标签集，模型种类，层数，token数，初始字向量来源，向量维数，训练算法，学习率，batch大小，训练epoch数）
2. （损失曲线，准确率曲线，每轮epoch记录损失，
3. （重要）参考论文！大模型辅助程度！


train tags freq: {'O': 17182664, 'B_T': 180819, 'I_T': 494698, 'B_LOC': 206640, 'I_LOC': 326891, 'B_ORG': 15081, 'I_ORG': 33203, 'B_PER': 182664, 'I_PER': 352243}
dev tags freq: {'O': 2238962, 'B_LOC': 28221, 'I_LOC': 44605, 'B_T': 22789, 'I_T': 61373, 'B_PER': 24871, 'I_PER': 48577, 'B_ORG': 1851, 'I_ORG': 4030}

其中标签'O'占比超过90%，样本分布严重不均衡
